{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gxucoder/Imageclassification_Resnet_Moblinet-_NasNet/blob/main/%E2%80%9C%E2%80%9CDone_Nasnetmobile_tflite_ipynb%E2%80%9D%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6M-agd6cQy2"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.applications.nasnet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import tempfile\n",
        "import sys\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "from tensorflow.lite.python import schema_py_generated\n",
        "if sys.version_info.major >= 3:\n",
        "    import pathlib\n",
        "else:\n",
        "    import pathlib2 as pathlib\n",
        "# schema_py_generated.Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ixqg9Ln8GU1"
      },
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow_model_optimization as tfmot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwVTYfyVwyrZ"
      },
      "source": [
        "!pip install keras-flops\n",
        "from keras_flops import get_flops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HfzFJhznAXZ"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "#from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "saQLarxOqJT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "dLNLxeLGqJtr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddD9VrDtnAXa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfhxP-o5nAXa"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RpfFRIpnAXb"
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhCh8c59nAXc"
      },
      "source": [
        "print(tf. __version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvdY42PdnAXe"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "# session.close()\n",
        "\n",
        "# 为确保pytorch运行 必须限制tf占用的内存\n",
        "# config = ConfigProto()\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
        "# # session = InteractiveSession().close()\n",
        "# session = InteractiveSession(config=config)\n",
        "# session.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IGd4To4nAXf"
      },
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UvIXCxtnAXf"
      },
      "source": [
        "def convert_bytes(size, unit=None):\n",
        "    if unit == 'KB':\n",
        "        return print('File size:' + str( round(size/ 1024, 3))+ 'kb')\n",
        "    elif unit == 'MB':\n",
        "        return print('File size:' + str( round(size/ (1024*1024), 3))+ 'Mb')\n",
        "    else:\n",
        "        return print('File size:' + str(size)+ 'bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXCb8qFWnAXg"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "  size = os.path.getsize(zipped_file)\n",
        "  print('File size:' + str( round(size/ (1024*1024), 3))+ 'Mb')\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdGaMO4FnAXg"
      },
      "source": [
        "def generate_train_data_from_directory(train_data_dir, image_target_size = 224, batch_size = 32, channels = 3, class_mode = 'categorical' ): \n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "            train_data_dir ,\n",
        "            target_size = (image_target_size, image_target_size),\n",
        "            batch_size  = batch_size,\n",
        "            class_mode  = class_mode)\n",
        "\n",
        "    total_images = train_generator.n  \n",
        "    steps = total_images//batch_size \n",
        "#iterations to cover all data, so if batch is 5, it will take total_images/5  iteration \n",
        "\n",
        "    train_images , train_labels = [] , []\n",
        "    for i in range(steps):\n",
        "        a , b = train_generator.next()\n",
        "        train_images.extend(a) \n",
        "        train_labels.extend(b)\n",
        "    \n",
        "    return np.array(train_images), np.array(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDLaStcpnAXh"
      },
      "source": [
        "def generate_test_data_from_directory(test_data_dir, image_target_size = 224, batch_size = 1, channels = 3, class_mode = 'categorical' ): \n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "            test_data_dir ,\n",
        "            target_size = (image_target_size, image_target_size),\n",
        "            batch_size  = batch_size,\n",
        "            class_mode  = class_mode)\n",
        "\n",
        "    total_images = test_generator.n  \n",
        "    steps = total_images//batch_size \n",
        "#iterations to cover all data, so if batch is 5, it will take total_images/5  iteration \n",
        "\n",
        "    test_images , test_labels = [] , []\n",
        "    for i in range(steps):\n",
        "        a , b = test_generator.next()\n",
        "        test_images.extend(a) \n",
        "        test_labels.extend(b)\n",
        "    \n",
        "    return np.array(test_images), np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP65BsBur3YJ"
      },
      "source": [
        "def inference_integer_tflite(mode_path, num_test):\n",
        "  interpreter = tf.lite.Interpreter(model_path=mode_path)\n",
        "\n",
        "  interpreter.allocate_tensors()\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  print('input_details:  ', interpreter.get_input_details())\n",
        "  print('output_details: ', interpreter.get_output_details())\n",
        "\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  inference_time = []\n",
        "\n",
        "  for batch in test.take(int(num_test)):\n",
        "    image = batch[0].numpy()\n",
        "\n",
        "    start_ms = time.time()\n",
        "    image = np.expand_dims(image,0).astype(np.uint8)\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], image)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "    elapsed_ms = time.time() - start_ms\n",
        "    inference_time.append(elapsed_ms * 1000.0)\n",
        "\n",
        "    if np.argmax(batch[1].numpy()) == np.argmax(predictions):\n",
        "      num_correct += 1\n",
        "    total_seen += 1\n",
        "\n",
        "    if total_seen % 500 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "        \n",
        "\n",
        "  print('Num images: {0:}, Accuracy: {1:.4f}, Latency: {2:.2f} ms'.format(num_test,\n",
        "                                                                         float(num_correct / total_seen),\n",
        "                                                                         np.array(inference_time).mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZQuRWpnAXh"
      },
      "source": [
        "def inference_tflite(mode_path, num_test):\n",
        "  interpreter = tf.lite.Interpreter(model_path=mode_path)\n",
        "\n",
        "  interpreter.allocate_tensors()\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  print('input_details:  ', interpreter.get_input_details())\n",
        "  print('output_details: ', interpreter.get_output_details())\n",
        "\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  inference_time = []\n",
        "\n",
        "  for batch in test.take(int(num_test)):\n",
        "    image = batch[0].numpy()\n",
        "\n",
        "    start_ms = time.time()\n",
        "    image = np.expand_dims(image,0).astype(np.float32)\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], image)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "    elapsed_ms = time.time() - start_ms\n",
        "    inference_time.append(elapsed_ms * 1000.0)\n",
        "\n",
        "    if np.argmax(batch[1].numpy()) == np.argmax(predictions):\n",
        "      num_correct += 1\n",
        "    total_seen += 1\n",
        "\n",
        "    if total_seen % 500 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "        \n",
        "\n",
        "  print('Num images: {0:}, Accuracy: {1:.4f}, Latency: {2:.2f} ms'.format(num_test,\n",
        "                                                                         float(num_correct / total_seen),\n",
        "                                                                         np.array(inference_time).mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwcSdZq2eufB"
      },
      "source": [
        "\n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2W0DjlbPgS"
      },
      "source": [
        "\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1wlS-gxh2jh"
      },
      "source": [
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxMvA_HPnAXj"
      },
      "source": [
        "num_test=len(x_test[:1000])\n",
        "print(num_test)\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykiZ3yJ7nAXj"
      },
      "source": [
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc2N1fZWnAXk"
      },
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip= True,\n",
        "                                    zoom_range=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRR1KddOoYZd"
      },
      "source": [
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kjb-ckqq_TQ"
      },
      "source": [
        "batch_size= 100\n",
        "epochs=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMObnLXvnAXk"
      },
      "source": [
        "test = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5QEAhbZexWK",
        "scrolled": false
      },
      "source": [
        "base_model = NASNetMobile(include_top=False, weights=None, input_shape=(32,32,3),classes=y_train.shape[1])\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "sgd = tf.keras.optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)    \n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics = ['accuracy'])    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpMYJk8qXZ-"
      },
      "source": [
        "model.fit(train_generator.flow(x_train,y_train,batch_size=batch_size),\n",
        "                      epochs=epochs,\n",
        "                      validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdH-fRnAnAXl"
      },
      "source": [
        "plt.plot(history.history['accuracy'])    #plot oringal model accuracy and loss\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('NASNetMobile no optimized model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vku3fKS8nAXl",
        "scrolled": false
      },
      "source": [
        "plt.plot(history.history['loss'])           #plot oringal model accuracy and loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('NASNetMobile no optimized model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw_7jN0cU2sF"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator.flow(x_test,y_test,batch_size=1), verbose=2)    #oringal model evaluation\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdlX7sRFwQUf"
      },
      "source": [
        "times = {}\n",
        "avg_times = []\n",
        "num_instances = [1,10,100,1000]#,10000]\n",
        "for instance in num_instances:\n",
        "  times[instance] = []\n",
        "num_rep = 100\n",
        "for inst_count in num_instances:\n",
        "  x_test_sample=x_test[0:inst_count]\n",
        "  batch_size = inst_count\n",
        "  for rep in range(num_rep):\n",
        "    start_time = time.time()\n",
        "    test_pred = model.predict(test_generator.flow(x_test_sample, batch_size=batch_size), verbose=0)    #oringal model evaluation\n",
        "    times[inst_count].append(time.time()-start_time)\n",
        "  avg_times.append(sum(times[inst_count])/num_rep)\n",
        "  print(inst_count)\n",
        "print(num_instances)\n",
        "print(avg_times)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_kSxWkUxB4I"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "p_test = model.predict(x_test)\n",
        "# cm = confusion_matrix(y_test, p_test)\n",
        "cm = confusion_matrix(tf.math.argmax(y_test, axis=1), tf.math.argmax(p_test, axis=1))\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFdY_yznxB7i"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(tf.math.argmax(p_test, axis=1), tf.math.argmax(y_test, axis=1), average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMbqMSjqxCAD"
      },
      "source": [
        "f1_score(tf.math.argmax(p_test, axis=1), tf.math.argmax(y_test, axis=1), average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4Gbj3-xP3H"
      },
      "source": [
        "f1_score(tf.math.argmax(p_test, axis=1), tf.math.argmax(y_test, axis=1), average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmPvNt1HxP8H"
      },
      "source": [
        "# Calculae FLOPS\n",
        "flops = get_flops(model, batch_size=1)\n",
        "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jleDPV0-xW7x"
      },
      "source": [
        "# def get_flops_from_model(model_h5_path):\n",
        "#     session = tf.compat.v1.Session()\n",
        "#     graph = tf.compat.v1.get_default_graph()\n",
        "        \n",
        "\n",
        "#     with graph.as_default():\n",
        "#         with session.as_default():\n",
        "#             model = tf.keras.models.load_model(model_h5_path)\n",
        "\n",
        "#             run_meta = tf.compat.v1.RunMetadata()\n",
        "#             opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "        \n",
        "#             # We use the Keras session graph in the call to the profiler.\n",
        "#             flops = tf.compat.v1.profiler.profile(graph=graph,\n",
        "#                           run_meta=run_meta, cmd='op', options=opts)\n",
        "        \n",
        "#             return flops.total_float_ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfGQm_OIxoIt"
      },
      "source": [
        "models_dir = pathlib.Path(os.path.join('.', 'models'))\n",
        "models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UCE-FpSxoMD"
      },
      "source": [
        "model.save(os.path.join(models_dir, 'Mobilenet.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuEbxP9mxrut"
      },
      "source": [
        "# print(f\"FLOPS: {get_flops_from_model(os.path.join(models_dir, 'Mobilenet.h5')) / 10 ** 9:.03} G\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAKSKu2ynAXm"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_TOsvK9nAXm"
      },
      "source": [
        "quantization aware training(with no quanti)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkVEbX6tnAXn"
      },
      "source": [
        "Quantize some layers\n",
        "Quantizing a model can have a negative effect on accuracy. You can selectively quantize layers of a model to explore the trade-off between accuracy, speed, and model size.\n",
        "\n",
        "Your use case:\n",
        "\n",
        "To deploy to a backend that only works well with fully quantized models (e.g. EdgeTPU v1, most DSPs), try \"Quantize whole model\".\n",
        "Tips for better model accuracy:\n",
        "\n",
        "It's generally better to finetune with quantization aware training as opposed to training from scratch.\n",
        "Try quantizing the later layers instead of the first layers.\n",
        "Avoid quantizing critical layers (e.g. attention mechanism).\n",
        "In the example below, quantize only the Dense layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXYsn8WDnAXn"
      },
      "source": [
        "# def apply_quantization_to_dense(layer):\n",
        "#   if isinstance(layer, tf.keras.layers.Dense):\n",
        "#     return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "#   return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtrJM1fMnAXo"
      },
      "source": [
        "# Use `tf.keras.models.clone_model` to apply `apply_quantization_to_dense` \n",
        "# to the layers of the model.\n",
        "# annotated_model = tf.keras.models.clone_model(\n",
        "#     model,\n",
        "#     clone_function=apply_quantization_to_dense,\n",
        "# )\n",
        "\n",
        "# # Now that the Dense layers are annotated,\n",
        "# # `quantize_apply` actually makes the model quantization aware.\n",
        "# q_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "\n",
        "# # `quantize_model` requires a recompile.\n",
        "# q_aware_model.compile('sgd',\n",
        "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "#               metrics=['accuracy'])\n",
        "# q_aware_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_lZN_eKnAXp",
        "scrolled": true
      },
      "source": [
        "# history =q_aware_model.fit(train_generator.flow(x_train,y_train,batch_size=batch_size), \n",
        "#                            validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size), initial_epoch=50, epochs=55)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juvOisfJnAXq"
      },
      "source": [
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('QAT model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['Training', 'Test'], loc='lower right')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgGZNhNmnAXq"
      },
      "source": [
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('QAT model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['Training', 'Test'], loc='lower right')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ1R0SWtnAXr"
      },
      "source": [
        "Convert model to TFlite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9uqnqtunAXr"
      },
      "source": [
        "models_dir = pathlib.Path(os.path.join('.', 'models'))\n",
        "models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5gBwZYynAXr"
      },
      "source": [
        "TFlite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh2wug_KnAXr"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter.experimental_new_converter = True\n",
        "tflite_model = converter.convert()\n",
        "with open(os.path.join(models_dir, 'NASNetMobile.tflite'), 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUFyeAj-nAXs"
      },
      "source": [
        "Dynamic range quantization (Post training quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFNKFpmnAXs"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# converter.experimental_new_converter = True\n",
        "# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_dynamic_quant_model = converter.convert()\n",
        "with open(os.path.join(models_dir, 'NASNetMobile_dynamic_quant.tflite'), 'wb') as f:\n",
        "    f.write(tflite_dynamic_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_hpIz7AnAXs"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_dynamic_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxB7HmWenAXs"
      },
      "source": [
        "Float16 quantization model (Post training quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYTIgmEXnAXs"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# converter.experimental_new_converter = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_fp16_quant_model = converter.convert()\n",
        "with open(os.path.join(models_dir, 'NASNetMobile_fp16_quant.tflite'), 'wb') as f:\n",
        "    f.write(tflite_fp16_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfRdYr5vnAXs"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_fp16_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYlWFrrKnAXt"
      },
      "source": [
        "Convert using dynamic range quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MG0q1V5nAXt"
      },
      "source": [
        "Convert using float fallback quantization\n",
        "To quantize the variable data (such as model input/output and intermediates between layers), you need to provide a RepresentativeDataset. This is a generator function that provides a set of input data that's large enough to represent typical values. It allows the converter to estimate a dynamic range for all the variable data. (The dataset does not need to be unique compared to the training or evaluation dataset.) To support multiple inputs, each representative data point is a list and elements in the list are fed to the model according to their indices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss8BxBWqnAXt"
      },
      "source": [
        "integer only quantization model (Post training quantization) int 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivcnzJVXnAXt",
        "scrolled": false
      },
      "source": [
        "def representative_dataset():\n",
        "  for data in tf.data.Dataset.from_tensor_slices((x_test)).batch(1).take(100):\n",
        "    yield [tf.dtypes.cast(data, tf.float32)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.inference_input_type = tf.uint8  # or tf.uint8\n",
        "converter.inference_output_type = tf.uint8  # or tf.uint8\n",
        "tflite_full_integer_quant_model = converter.convert()\n",
        "\n",
        "with open(os.path.join(models_dir, 'NASNetMobile_integer_quant.tflite'), 'wb') as f:\n",
        "    f.write(tflite_full_integer_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej0DmNx3nAXt"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_full_integer_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TocicRN2nAXt"
      },
      "source": [
        "Integer quantization model (Quantization aware training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIfifcPenAXt"
      },
      "source": [
        "# #with tfmo.quantization.keras.quantize_scope():\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "\n",
        "# converter.experimental_new_converter = True\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# tflite_q_aware_integer_quant_model = converter.convert()\n",
        "# with open(os.path.join(models_dir, 'NASNetMobile_q_aware_integer_quant.tflite'), 'wb') as f:\n",
        "#     f.write(tflite_q_aware_integer_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ydbYsD4nAXu"
      },
      "source": [
        "test tflite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPLiiLfynAXv"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0SeJfNFnAXv"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc0z-5PGnAXv"
      },
      "source": [
        "integer only quantization model (Post training quantization) int 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b64ArR4nAXv"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile_integer_quant.tflite')\n",
        "inference_integer_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXqyNSoInAXw"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_integer_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5hyb50nAXw"
      },
      "source": [
        "dynamic range quantization (Post training quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7NCOlSHnAXw"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile_dynamic_quant.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZc4AqDynAXw"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_dynamic_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hf3u4fVnAXw"
      },
      "source": [
        "Float16 quantization model (Post training quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKinoiK5nAXw"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile_fp16_quant.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9JgrLN-nAXx"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_fp16_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRvAxg3OnAXx"
      },
      "source": [
        "Integer only: 16-bit activations with 8-bit weights (experimental)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZXdszpInAXx"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile_integer_quant.tflite')\n",
        "inference_integer_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNGcONBCnAXx"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_integer_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cwr9iFonAXx"
      },
      "source": [
        "Integer quantization model (Quantization aware training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPJdylcLnAXx"
      },
      "source": [
        "# model_path = os.path.join(models_dir, 'NASNetMobile_q_aware_integer_quant.tflite')\n",
        "# inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpEovvIVnAXy"
      },
      "source": [
        "# convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_q_aware_integer_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-83LZAgknAXy"
      },
      "source": [
        "pruning and quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyQyjhGMnAXy"
      },
      "source": [
        "# x,y = train_generator.next()\n",
        "image = x_train[0]\n",
        "label = y_train[0]\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "epochs = 5\n",
        "validation_split = 0.25\n",
        "num_images = image.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                               final_sparsity=0.300,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile('sgd',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf317_hwgDqQ"
      },
      "source": [
        "print(num_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHEk1yQenAXy"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "history = model_for_pruning.fit(train_generator.flow(x_train,y_train,batch_size=batch_size), \n",
        "                                validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),\n",
        "                                callbacks=callbacks,\n",
        "                                epochs=5, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8wqbUpXnAXy"
      },
      "source": [
        "plt.plot(history.history['accuracy'])    #plot oringal model accuracy and loss\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('pruned model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx6eYGQ6nAXy"
      },
      "source": [
        "plt.plot(history.history['loss'])           #plot oringal model accuracy and loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('pruned model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGNboWKdnAXz"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_generator.flow(x_test,y_test,batch_size=1), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHZDNveBnAXz"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "\n",
        "model_for_pruning.save(os.path.join(models_dir, 'NASNetMobile_prund.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPzRJHInnAXz",
        "scrolled": true
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(os.path.join(models_dir, 'NASNetMobile_pruned.tflite'), 'wb') as f:\n",
        "    f.write(pruned_tflite_model)\n",
        "\n",
        "# print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7JkmNZGnAXz"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile_pruned.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqSodZvdnAXz"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_pruned.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB5_vjR1nAX0"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(os.path.join(models_dir, 'NASNetMobile_quant_and_pruned.tflite'), 'wb') as f:\n",
        "    f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "\n",
        "# print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "# print(\"Size of gzipped baseline Keras model: %.2f bytes\" %(get_gzipped_model_size(keras_file)))\n",
        "# print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JkDpu8jnAX0"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'NASNetMobile_quant_and_pruned.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4z1PK5TnAX0"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_quant_and_pruned.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC7L4UfanAX0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8fwNOEnAXu"
      },
      "source": [
        "# Save keras model\n",
        "model.save(os.path.join(models_dir, 'NASNetMobile.h5'))\n",
        "# q_aware_model.save(os.path.join(models_dir, 'NASNetMobile_quant.h5'))\n",
        "model_for_pruning.save(os.path.join(models_dir, 'NASNetMobile_pruned.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vG6S9Dg0oDN"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_pruned.h5')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBaO49JqnAXu"
      },
      "source": [
        "# convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile_quant.h5')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyDrtbrrnAXu"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'NASNetMobile.h5')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjbZhK-a14UR"
      },
      "source": [
        "get_gzipped_model_size(os.path.join(models_dir, 'NASNetMobile.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuhCY01p15TZ"
      },
      "source": [
        "# get_gzipped_model_size(os.path.join(models_dir, 'NASNetMobile_quant.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ea2mPLs1R6y"
      },
      "source": [
        "get_gzipped_model_size(os.path.join(models_dir, 'NASNetMobile_pruned.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}