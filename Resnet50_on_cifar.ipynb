{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gxucoder/Imageclassification_Resnet_Moblinet-_NasNet/blob/main/Resnet50_on_cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6M-agd6cQy2"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.lite.python import schema_py_generated\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "if sys.version_info.major >= 3:\n",
        "    import pathlib\n",
        "else:\n",
        "    import pathlib2 as pathlib\n",
        "from keras_flops import get_flops\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np       # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import tempfile\n",
        "import itertools\n",
        "import sys\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvdY42PdnAXe"
      },
      "source": [
        "#Use GPU instead of CPU, ensure the model is able to take up a certain amount of GPU memory. \n",
        "\n",
        "#from tensorflow.compat.v1 import ConfigProto\n",
        "#from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "#config = ConfigProto()\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
        "#config.gpu_options.allow_growth = True\n",
        "#session = InteractiveSession(config=config)\n",
        "# session.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IGd4To4nAXf"
      },
      "source": [
        "#Get the size of the file under the path below\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UvIXCxtnAXf"
      },
      "source": [
        "#convert file unit from Bit to bytes\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == 'KB':\n",
        "        return print('File size:' + str( round(size/ 1024, 3))+ 'kb')\n",
        "    elif unit == 'MB':\n",
        "        return print('File size:' + str( round(size/ (1024*1024), 3))+ 'Mb')\n",
        "    else:\n",
        "        return print('File size:' + str(size)+ 'bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXCb8qFWnAXg"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "  size = os.path.getsize(zipped_file)\n",
        "  print('File size:' + str( round(size/ (1024*1024), 3))+ 'Mb')\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdGaMO4FnAXg"
      },
      "source": [
        "def generate_train_data_from_directory(train_data_dir, image_target_size = 224, batch_size = 32, channels = 3, class_mode = 'categorical' ): \n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "            train_data_dir ,\n",
        "            target_size = (image_target_size, image_target_size),\n",
        "            batch_size  = batch_size,\n",
        "            class_mode  = class_mode)\n",
        "\n",
        "    total_images = train_generator.n  \n",
        "    steps = total_images//batch_size \n",
        "#iterations to cover all data, so if batch is 5, it will take total_images/5  iteration \n",
        "\n",
        "    train_images , train_labels = [] , []\n",
        "    for i in range(steps):\n",
        "        a , b = train_generator.next()\n",
        "        train_images.extend(a) \n",
        "        train_labels.extend(b)\n",
        "    \n",
        "    return np.array(train_images), np.array(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDLaStcpnAXh"
      },
      "source": [
        "def generate_test_data_from_directory(test_data_dir, image_target_size = 224, batch_size = 1, channels = 3, class_mode = 'categorical' ): \n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "            test_data_dir ,\n",
        "            target_size = (image_target_size, image_target_size),\n",
        "            batch_size  = batch_size,\n",
        "            class_mode  = class_mode)\n",
        "\n",
        "    total_images = test_generator.n  \n",
        "    steps = total_images//batch_size \n",
        "#iterations to cover all data, so if batch is 5, it will take total_images/5  iteration \n",
        "\n",
        "    test_images , test_labels = [] , []\n",
        "    for i in range(steps):\n",
        "        a , b = test_generator.next()\n",
        "        test_images.extend(a) \n",
        "        test_labels.extend(b)\n",
        "    \n",
        "    return np.array(test_images), np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP65BsBur3YJ"
      },
      "source": [
        "def inference_integer_tflite(mode_path, num_ingeter_test):\n",
        "  interpreter = tf.lite.Interpreter(model_path=mode_path)\n",
        "\n",
        "  interpreter.allocate_tensors()\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  print('input_details:  ', interpreter.get_input_details())\n",
        "  print('output_details: ', interpreter.get_output_details())\n",
        "\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  inference_time = []\n",
        "\n",
        "  for batch in test.take(int(num_test)):\n",
        "    image = batch[0].numpy()\n",
        "\n",
        "    start_ms = time.time()\n",
        "    image = np.expand_dims(image,0).astype(np.uint8)\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], image)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "    elapsed_ms = time.time() - start_ms\n",
        "    inference_time.append(elapsed_ms * 1000.0)\n",
        "\n",
        "    if np.argmax(batch[1].numpy()) == np.argmax(predictions):\n",
        "      num_correct += 1\n",
        "    total_seen += 1\n",
        "\n",
        "    if total_seen % 50 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "        \n",
        "\n",
        "  print('Num images: {0:}, Accuracy: {1:.4f}, Latency: {2:.2f} ms'.format(num_test,\n",
        "                                                                         float(num_correct / total_seen),\n",
        "                                                                         np.array(inference_time).mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZQuRWpnAXh"
      },
      "source": [
        "def inference_tflite(mode_path, num_test):\n",
        "  interpreter = tf.lite.Interpreter(model_path=mode_path)\n",
        "\n",
        "  interpreter.allocate_tensors()\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  print('input_details:  ', interpreter.get_input_details())\n",
        "  print('output_details: ', interpreter.get_output_details())\n",
        "\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  inference_time = []\n",
        "\n",
        "  for batch in test.take(int(num_test)):\n",
        "    image = batch[0].numpy()\n",
        "\n",
        "    start_ms = time.time()\n",
        "    image = np.expand_dims(image,0).astype(np.float32)\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], image)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "    elapsed_ms = time.time() - start_ms\n",
        "    inference_time.append(elapsed_ms * 1000.0)\n",
        "\n",
        "    if np.argmax(batch[1].numpy()) == np.argmax(predictions):\n",
        "      num_correct += 1\n",
        "    total_seen += 1\n",
        "\n",
        "    if total_seen % 500 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "        \n",
        "\n",
        "  print('Num images: {0:}, Accuracy: {1:.4f}, Latency: {2:.2f} ms'.format(num_test,\n",
        "                                                                         float(num_correct / total_seen),\n",
        "                                                                         np.array(inference_time).mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwcSdZq2eufB"
      },
      "source": [
        "##for flower recongnise dataset, which I saved locally\n",
        "# train_data_dir = r\"C:/...flower_dataset/train\"\n",
        "# test_data_dir  = r\"C:/...flower_dataset/test\"\n",
        "# img_height, img_width = (32,32)\n",
        "# image_size=(32,32)\n",
        "# batch_size = 64\n",
        "\n",
        "#load cifar10 data \n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2W0DjlbPgS"
      },
      "source": [
        "#split train and test data\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1wlS-gxh2jh"
      },
      "source": [
        "#print out info of train and test dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxMvA_HPnAXj"
      },
      "source": [
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ6ehXan2Nne"
      },
      "source": [
        "num_test=len(x_test[:1000])\n",
        "print(num_test)\n",
        "num_integer_test= len(x_test[:1000])\n",
        "print(num_integer_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykiZ3yJ7nAXj"
      },
      "source": [
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc2N1fZWnAXk"
      },
      "source": [
        "#Transform images into a larger and more robust dataset\n",
        "train_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip= True,\n",
        "                                    zoom_range=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRR1KddOoYZd"
      },
      "source": [
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kjb-ckqq_TQ"
      },
      "source": [
        "batch_size= 300\n",
        "epochs=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMObnLXvnAXk"
      },
      "source": [
        "test = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5QEAhbZexWK",
        "scrolled": false
      },
      "source": [
        "base_model = ResNet50(include_top=False, weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "    \n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9Stx_CIdjx"
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpMYJk8qXZ-"
      },
      "source": [
        "model.fit(train_generator.flow(x_train,y_train,batch_size=batch_size),\n",
        "                      epochs=epochs,\n",
        "                      validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),callbacks = [tensorboard_callback] ,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdH-fRnAnAXl"
      },
      "source": [
        "plt.plot(history.history['accuracy'])    #plot oringal model accuracy and loss\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Resnet50 no optimized model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vku3fKS8nAXl",
        "scrolled": false
      },
      "source": [
        "plt.plot(history.history['loss'])           #plot oringal model accuracy and loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Resnet50 no optimized model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBGGa4g8HPgK"
      },
      "source": [
        "y_pred = model.predict(test_generator.flow(x_test), verbose=2)    #oringal model evaluation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2897j5WZj9C"
      },
      "source": [
        "from sklearn.metrics import classification_report  \n",
        "print(classification_report(tf.math.argmax(y_pred, axis=1), tf.math.argmax(y_test, axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw_7jN0cU2sF"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator.flow(x_test,y_test,batch_size=100), verbose=2)    #oringal model evaluation\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ZvgV6cj3zV"
      },
      "source": [
        "\n",
        "# times = {}\n",
        "# avg_times = []\n",
        "# num_instances = [1,10,100,1000]#,10000]\n",
        "# for instance in num_instances:\n",
        "#   times[instance] = []\n",
        "# num_rep = 100\n",
        "# for inst_count in num_instances:\n",
        "#   x_test_sample=x_test[0:inst_count]\n",
        "#   batch_size = inst_count\n",
        "#   for rep in range(num_rep):\n",
        "#     start_time = time.time()\n",
        "#     test_pred = model.predict(test_generator.flow(x_test_sample, batch_size=batch_size), verbose=0)    #oringal model evaluation\n",
        "#     times[inst_count].append(time.time()-start_time)\n",
        "#   avg_times.append(sum(times[inst_count])/num_rep)\n",
        "#   print(inst_count)\n",
        "# print(num_instances)\n",
        "# print(avg_times)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDRl5nVZeT-s"
      },
      "source": [
        "#Plot heat map for model \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "p_test = model.predict(x_test)\n",
        "# cm = confusion_matrix(y_test, p_test)\n",
        "cm = confusion_matrix(tf.math.argmax(y_test, axis=1), tf.math.argmax(p_test, axis=1))\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGGcO_ef6jiG"
      },
      "source": [
        "A more general F score, that uses a positive real factor β, where β is chosen such that recall is considered β times as important as precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lgw6V0pbISL"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(tf.math.argmax(p_test, axis=1), tf.math.argmax(y_test, axis=1), average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGexMncxtRrf"
      },
      "source": [
        "f1_score(tf.math.argmax(p_test, axis=1), tf.math.argmax(y_test, axis=1), average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCyqpjoBtVQF"
      },
      "source": [
        "f1_score(tf.math.argmax(p_test, axis=1), tf.math.argmax(y_test, axis=1), average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKF7oQia85nG"
      },
      "source": [
        "# Calculae FLOPS\n",
        "flops = get_flops(model, batch_size=1)\n",
        "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCiEBH95w6Id"
      },
      "source": [
        "models_dir = pathlib.Path(os.path.join('.', 'models'))\n",
        "models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEjseVTFLCZo"
      },
      "source": [
        "model.save(os.path.join(models_dir, 'Resnet50.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_TOsvK9nAXm"
      },
      "source": [
        "quantization aware training(with no quanti)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkVEbX6tnAXn"
      },
      "source": [
        "Quantize some layers\n",
        "Quantizing a model can have a negative effect on accuracy. You can selectively quantize layers of a model to explore the trade-off between accuracy, speed, and model size.\n",
        "\n",
        "Your use case:\n",
        "\n",
        "To deploy to a backend that only works well with fully quantized models (e.g. EdgeTPU v1, most DSPs), try \"Quantize whole model\".\n",
        "Tips for better model accuracy:\n",
        "\n",
        "It's generally better to finetune with quantization aware training as opposed to training from scratch.\n",
        "Try quantizing the later layers instead of the first layers.\n",
        "Avoid quantizing critical layers (e.g. attention mechanism).\n",
        "In the example below, quantize only the Dense layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXYsn8WDnAXn"
      },
      "source": [
        "# def apply_quantization_to_dense(layer):\n",
        "#   if isinstance(layer, tf.keras.layers.Dense):\n",
        "#     return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "#   return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtrJM1fMnAXo"
      },
      "source": [
        "# # Use `tf.keras.models.clone_model` to apply `apply_quantization_to_dense` \n",
        "# # to the layers of the model.\n",
        "# annotated_model = tf.keras.models.clone_model(\n",
        "#     model,\n",
        "#     clone_function=apply_quantization_to_dense,\n",
        "# )\n",
        "\n",
        "# # Now that the Dense layers are annotated,\n",
        "# # `quantize_apply` actually makes the model quantization aware.\n",
        "# q_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "\n",
        "# # `quantize_model` requires a recompile.\n",
        "# q_aware_model.compile('adam',\n",
        "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "#               metrics=['accuracy'])\n",
        "# # q_aware_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_lZN_eKnAXp",
        "scrolled": true
      },
      "source": [
        "# history =q_aware_model.fit(train_generator.flow(x_train,y_train,batch_size=batch_size), \n",
        "#                            validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size), initial_epoch=50, epochs=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juvOisfJnAXq"
      },
      "source": [
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('QAT model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['Training', 'Test'], loc='lower right')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgGZNhNmnAXq"
      },
      "source": [
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('QAT model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['Training', 'Test'], loc='lower right')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ1R0SWtnAXr"
      },
      "source": [
        "**Convert model to TFlite model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh2wug_KnAXr"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter.experimental_new_converter = True\n",
        "tflite_model = converter.convert()\n",
        "with open(os.path.join(models_dir, 'Resnet50.tflite'), 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUFyeAj-nAXs"
      },
      "source": [
        "**Dynamic range quantization (Post training quantization)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFNKFpmnAXs"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# converter.experimental_new_converter = True\n",
        "# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_dynamic_quant_model = converter.convert()\n",
        "with open(os.path.join(models_dir, 'Resnet50_dynamic_quant.tflite'), 'wb') as f:\n",
        "    f.write(tflite_dynamic_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_hpIz7AnAXs"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_dynamic_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxB7HmWenAXs"
      },
      "source": [
        "**Float16 quantization model (Post training quantization)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYTIgmEXnAXs"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# converter.experimental_new_converter = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_fp16_quant_model = converter.convert()\n",
        "with open(os.path.join(models_dir, 'Resnet50_fp16_quant.tflite'), 'wb') as f:\n",
        "    f.write(tflite_fp16_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfRdYr5vnAXs"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_fp16_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYlWFrrKnAXt"
      },
      "source": [
        "Convert using dynamic range quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MG0q1V5nAXt"
      },
      "source": [
        "Convert using float fallback quantization\n",
        "To quantize the variable data (such as model input/output and intermediates between layers), you need to provide a RepresentativeDataset. This is a generator function that provides a set of input data that's large enough to represent typical values. It allows the converter to estimate a dynamic range for all the variable data. (The dataset does not need to be unique compared to the training or evaluation dataset.) To support multiple inputs, each representative data point is a list and elements in the list are fed to the model according to their indices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss8BxBWqnAXt"
      },
      "source": [
        "**Integer only quantization model (Post training quantization) Int 8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivcnzJVXnAXt",
        "scrolled": false
      },
      "source": [
        "def representative_dataset():\n",
        "  for data in tf.data.Dataset.from_tensor_slices((x_test)).batch(1).take(100):\n",
        "    yield [tf.dtypes.cast(data, tf.float32)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.inference_input_type = tf.uint8  # or tf.uint8\n",
        "converter.inference_output_type = tf.uint8  # or tf.uint8\n",
        "tflite_full_integer_quant_model = converter.convert()\n",
        "\n",
        "with open(os.path.join(models_dir, 'Resnet50_integer_quant.tflite'), 'wb') as f:\n",
        "    f.write(tflite_full_integer_quant_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej0DmNx3nAXt"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_full_integer_quant_model)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TocicRN2nAXt"
      },
      "source": [
        "Integer quantization model (Quantization aware training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ydbYsD4nAXu"
      },
      "source": [
        "**Test TFlite model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPLiiLfynAXv"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0SeJfNFnAXv"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc0z-5PGnAXv"
      },
      "source": [
        "integer only quantization model (Post training quantization) int 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b64ArR4nAXv"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50_integer_quant.tflite')\n",
        "inference_integer_tflite(model_path, int(num_integer_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXqyNSoInAXw"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_integer_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5hyb50nAXw"
      },
      "source": [
        "dynamic range quantization (Post training quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7NCOlSHnAXw"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50_dynamic_quant.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZc4AqDynAXw"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_dynamic_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hf3u4fVnAXw"
      },
      "source": [
        "Float16 quantization model (Post training quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKinoiK5nAXw"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50_fp16_quant.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9JgrLN-nAXx"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_fp16_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRvAxg3OnAXx"
      },
      "source": [
        "Integer only: 16-bit activations with 8-bit weights (experimental)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZXdszpInAXx"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50_integer_quant.tflite')\n",
        "inference_integer_tflite(model_path, int(num_integer_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNGcONBCnAXx"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_integer_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cwr9iFonAXx"
      },
      "source": [
        "Integer quantization model (Quantization aware training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPJdylcLnAXx"
      },
      "source": [
        "# model_path = os.path.join(models_dir, 'Resnet50_q_aware_integer_quant.tflite')\n",
        "# inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpEovvIVnAXy"
      },
      "source": [
        "# convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_q_aware_integer_quant.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-83LZAgknAXy"
      },
      "source": [
        "pruning and quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyQyjhGMnAXy"
      },
      "source": [
        "# Pruning a deep learning model involves removing some of its parameters or connections to reduce \n",
        "#the model's size and complexity without sacrificing its performance.\n",
        "\n",
        "# Using initial_sparsity and final_sparsity, determine what percentages should be pruned before and after. \n",
        "# Begin_step and end_step determine the layer you want to start on and end on.\n",
        "\n",
        "#For exammle here begin with 30% and end up with 70%\n",
        "image = x_train[0]\n",
        "label = y_train[0]\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "epochs = 2\n",
        "validation_split = 0.25\n",
        "num_images = image.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.70,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile('adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0dJ0mVeLXHU"
      },
      "source": [
        "image = x_train[0]\n",
        "label = y_train[0]\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "epochs = 5\n",
        "validation_split = 0.25\n",
        "num_images = image.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.30,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning1 = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning1.compile('adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ttg0jkxLiB_"
      },
      "source": [
        "image = x_train[0]\n",
        "label = y_train[0]\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "epochs = 5\n",
        "validation_split = 0.25\n",
        "num_images = image.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
        "                                                               final_sparsity=0.70,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning2 = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning2.compile('adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHEk1yQenAXy"
      },
      "source": [
        "#pruning fit for 30/70\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_generator.flow(x_train,y_train,batch_size=batch_size), \n",
        "                                validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),\n",
        "                                callbacks=callbacks,\n",
        "                                epochs=2, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5REr7KeWLyO1"
      },
      "source": [
        "##pruning fit for 20/30\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning1.fit(train_generator.flow(x_train,y_train,batch_size=batch_size), \n",
        "                                validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),\n",
        "                                callbacks=callbacks,\n",
        "                                epochs=3, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPGp8fbHL2jc"
      },
      "source": [
        "#pruning fit for 20/70\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning2.fit(train_generator.flow(x_train,y_train,batch_size=batch_size), \n",
        "                                validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),\n",
        "                                callbacks=callbacks,\n",
        "                                epochs=5, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGNboWKdnAXz"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_generator.flow(x_test,y_test,batch_size=1), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCNhBDM0M7YY"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning1.evaluate(\n",
        "   test_generator.flow(x_test,y_test,batch_size=1), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBiaBfDOM8ig"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning2.evaluate(\n",
        "   test_generator.flow(x_test,y_test,batch_size=1), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHZDNveBnAXz"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "model_for_pruning.save(os.path.join(models_dir, 'Resnet50_prund.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkfF8Fw6NdZm"
      },
      "source": [
        "model_for_export1 = tfmot.sparsity.keras.strip_pruning(model_for_pruning1)\n",
        "model_for_pruning1.save(os.path.join(models_dir, 'Resnet50_prund1.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IzY00WaNyW7"
      },
      "source": [
        "model_for_export2 = tfmot.sparsity.keras.strip_pruning(model_for_pruning2)\n",
        "model_for_pruning2.save(os.path.join(models_dir, 'Resnet50_prund2.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPzRJHInnAXz",
        "scrolled": true
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(os.path.join(models_dir, 'Resnet50_pruned.tflite'), 'wb') as f:\n",
        "    f.write(pruned_tflite_model)\n",
        "\n",
        "# print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22xQegIOEli"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export1)\n",
        "pruned_tflite_model1 = converter.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(os.path.join(models_dir, 'Resnet50_pruned1.tflite'), 'wb') as f:\n",
        "    f.write(pruned_tflite_model1)\n",
        "\n",
        "# print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH0024AeOEp8"
      },
      "source": [
        "converter1 = tf.lite.TFLiteConverter.from_keras_model(model_for_export2)\n",
        "pruned_tflite_model2 = converter1.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(os.path.join(models_dir, 'Resnet50_pruned2.tflite'), 'wb') as f:\n",
        "    f.write(pruned_tflite_model2)\n",
        "\n",
        "# print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7JkmNZGnAXz"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50_pruned1.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqSodZvdnAXz"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_pruned.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcUV0tQeOcIb"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_pruned1.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc5QZU1mOcRB"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_pruned2.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB5_vjR1nAX0"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(os.path.join(models_dir, 'Resnet50_quant_and_pruned.tflite'), 'wb') as f:\n",
        "    f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "\n",
        "# print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "# print(\"Size of gzipped baseline Keras model: %.2f bytes\" %(get_gzipped_model_size(keras_file)))\n",
        "# print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JkDpu8jnAX0"
      },
      "source": [
        "model_path = os.path.join(models_dir, 'Resnet50_quant_and_pruned.tflite')\n",
        "inference_tflite(model_path, int(num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4z1PK5TnAX0"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_quant_and_pruned.tflite')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC7L4UfanAX0"
      },
      "source": [
        "model.save(os.path.join(models_dir, 'Resnet50.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8fwNOEnAXu"
      },
      "source": [
        "# Save keras model\n",
        "# model.save(os.path.join(models_dir, 'Resnet50.h5'))\n",
        "# q_aware_model.save(os.path.join(models_dir, 'Resnet50_quant.h5'))\n",
        "model_for_pruning2.save(os.path.join(models_dir, 'Resnet50_pruned2.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vG6S9Dg0oDN"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_pruned2.h5')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBaO49JqnAXu"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50.h5')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyDrtbrrnAXu"
      },
      "source": [
        "convert_bytes(get_file_size(os.path.join(models_dir, 'Resnet50_prund.h5')),'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjbZhK-a14UR"
      },
      "source": [
        "get_gzipped_model_size(os.path.join(models_dir, 'Resnet50_prund.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuhCY01p15TZ"
      },
      "source": [
        "get_gzipped_model_size(os.path.join(models_dir, 'Resnet50.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ea2mPLs1R6y"
      },
      "source": [
        "get_gzipped_model_size(os.path.join(models_dir, 'Resnet50_prund.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdwp6P4eRfAo"
      },
      "source": [
        "flops = get_flops(model_for_pruning, batch_size=1)\n",
        "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKLOubWTRfPm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}